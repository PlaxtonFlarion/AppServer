#   ____  ____    ____  _
#  |  _ \|___ \  / ___|| |_ ___  _ __ __ _  __ _  ___
#  | |_) | __) | \___ \| __/ _ \| '__/ _` |/ _` |/ _ \
#  |  _ < / __/   ___) | || (_) | | | (_| | (_| |  __/
#  |_| \_\_____| |____/ \__\___/|_|  \__,_|\__, |\___|
#                                          |___/
#

import os
import boto3
import typing
import asyncio
import zipfile
from pathlib import Path
from loguru import logger
from botocore.client import Config
from boto3.s3.transfer import TransferConfig
from common import (
    const, utils
)

env = utils.current_env(
    const.R2_BUCKET_KEY, const.R2_BUCKET_USR, const.R2_BUCKET_PWD,
    const.R2_BUCKET_URL, const.R2_PUBLIC_URL
)

r2_bucket_key = env[const.R2_BUCKET_KEY]
r2_bucket_usr = env[const.R2_BUCKET_USR]
r2_bucket_pwd = env[const.R2_BUCKET_PWD]
r2_bucket_url = env[const.R2_BUCKET_URL]
r2_public_url = env[const.R2_PUBLIC_URL]

r2_client = boto3.client(
    "s3",
    endpoint_url=r2_bucket_url,
    aws_access_key_id=r2_bucket_usr,
    aws_secret_access_key=r2_bucket_pwd,
    config=Config(signature_version="s3v4"),
    region_name="auto"
)


async def upload_file(
    key: str,
    content: bytes,
    content_type: str,
    disposition_filename: str
) -> str:
    """
    ä¸Šä¼ ä»»æ„æ–‡ä»¶è‡³ R2ã€‚é»˜è®¤è®¾ç½®ä¸ºç§æœ‰å¯¹è±¡ï¼Œå¯é€šè¿‡ç­¾åè®¿é—®ã€‚
    """
    extra = {
        "ContentType": content_type,
        "ContentDisposition": f'inline; filename="{disposition_filename}"'
    }

    await asyncio.to_thread(
        r2_client.put_object, Bucket=const.BUCKET, Key=key, Body=content, **extra
    )
    logger.info(f"R2 ä¸Šä¼ å®Œæˆ -> {key}")
    return key


async def signed_url_for_stream(
    key: str,
    expires_in: int,
    disposition_filename: str
) -> str:
    """
    ç”Ÿæˆæ”¯æŒæ’­æ”¾ + ä¸‹è½½çš„ç­¾å URLï¼ŒContent-Disposition ä¸º inlineã€‚
    """
    signed_url = await asyncio.to_thread(
        r2_client.generate_presigned_url, "get_object",
        Params={
            "Bucket": const.BUCKET,
            "Key": key,
            "ResponseContentDisposition": f'inline; filename="{disposition_filename}"'
        },
        ExpiresIn=expires_in
    )
    logger.info(f"R2 ç­¾åå®Œæˆ -> {key}")
    return signed_url


async def file_exists(key: str) -> typing.Optional[bool]:
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨äºŽ R2ã€‚
    """
    try:
        await asyncio.to_thread(
            r2_client.head_object, Bucket=const.BUCKET, Key=key
        )
        return True
    except r2_client.exceptions.ClientError as e:
        if e.response["Error"]["Code"] == "404":
            return False
        logger.error(f"R2 æ£€æŸ¥å¤±è´¥: {e}")


async def compress_and_upload_folder(
    folder_path: str,
    r2_prefix: str,
    display_name: str,
    *,
    bucket: str = const.BUCKET
) -> dict:
    """
    åŽ‹ç¼©æŒ‡å®šæ–‡ä»¶å¤¹å¹¶ä¸Šä¼ è‡³ R2 å­˜å‚¨ã€‚

    Parameters
    ----------
    folder_path : str
        æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚

    r2_prefix : str
        ä¸Šä¼ åˆ° R2 çš„ç›®æ ‡è·¯å¾„å‰ç¼€ï¼ˆå¦‚ "model-store"ï¼‰ã€‚

    display_name : str
        ç”¨ä½œåŽ‹ç¼©åŒ…æ–‡ä»¶åå’Œå½’æ¡£ç›¸å¯¹è·¯å¾„çš„å‘½åã€‚

    bucket : str, optional
        R2 çš„å­˜å‚¨æ¡¶åç§°ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€ const.BUCKETã€‚

    Returns
    -------
    dict
        æ–‡ä»¶å…ƒæ•°æ®ä¿¡æ¯ã€‚
    """
    folder_path = Path(folder_path)
    if not folder_path.exists() or not folder_path.is_dir():
        raise FileNotFoundError(f"âŒ ç›®å½•ä¸å­˜åœ¨: {folder_path}")

    file_count = sum(len(files) for _, _, files in os.walk(folder_path))
    if file_count == 0:
        raise ValueError(f"âŒ ç›®å½•ä¸ºç©ºï¼Œæ— æ³•åŽ‹ç¼©ä¸Šä¼ : {folder_path}")

    zip_filename = f"{display_name}.zip"
    zip_path = Path("/tmp") / zip_filename

    try:
        # åŽ‹ç¼©ç›®å½•
        logger.info(f"ðŸ“¦ åŽ‹ç¼©ç›®å½• {folder_path} åˆ° {zip_path}")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, _, files in os.walk(folder_path):
                for file in files:
                    abs_path = os.path.join(root, file)
                    rel_path = os.path.relpath(abs_path, folder_path)
                    zipf.write(abs_path, arcname=os.path.join(display_name, rel_path))
        logger.success(f"âœ… ç›®å½•å·²åŽ‹ç¼©ä¸º {zip_path}")

        # ä¸Šä¼ é…ç½®
        config = TransferConfig(
            multipart_threshold=50 * 1024 * 1024,
            multipart_chunksize=50 * 1024 * 1024
        )
        r2_key = f"{r2_prefix.rstrip('/')}/{zip_filename}"

        logger.info(f"ðŸš€ ä¸Šä¼ åˆ° R2: {bucket}/{r2_key}")
        await asyncio.to_thread(
            r2_client.upload_file,
            Filename=str(zip_path),
            Bucket=bucket,
            Key=r2_key,
            ExtraArgs={
                "ContentType": "application/zip",
                "ContentDisposition": f'attachment; filename="{zip_filename}"'
            },
            Config=config
        )
        logger.success(f"âœ… ä¸Šä¼ æˆåŠŸ: {r2_key}")

        # æž„å»ºå…ƒä¿¡æ¯
        metadata = utils.generate_metadata(zip_path, display_name)
        logger.success(metadata)

        return metadata

    finally:
        # æ¸…ç†ä¸´æ—¶åŽ‹ç¼©åŒ…
        if zip_path.exists():
            await asyncio.to_thread(os.remove, zip_path)
            logger.info(f"ðŸ§¹ æœ¬åœ°åŽ‹ç¼©æ–‡ä»¶å·²æ¸…ç†: {zip_path}")


async def main() -> None:
    pass


if __name__ == '__main__':
    pass
